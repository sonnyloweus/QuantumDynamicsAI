{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "q4ns8pdIBhQb",
    "7lOv4H9iBVGJ"
   ],
   "authorship_tag": "ABX9TyO2+HhMgcSkau+jZyzzWrPw",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# File Setup"
   ],
   "metadata": {
    "id": "q4ns8pdIBhQb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "directory_path = ''\n",
    "\n",
    "#from google.colab import drive\n",
    "#import sys\n",
    "#drive.mount('/content/drive')\n",
    "#directory_path = '/content/drive/MyDrive/Quantum/'\n",
    "#sys.path.append('/content/drive/MyDrive/Quantum')\n",
    "# print(os.listdir(directory_path))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j10YqJU051l8",
    "outputId": "72930d25-1de5-4e9d-c619-e29b6099f1a9",
    "ExecuteTime": {
     "end_time": "2024-07-18T20:06:00.067969Z",
     "start_time": "2024-07-18T20:06:00.063769Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dense_small.param', '.DS_Store', 'quantum_experiments', 'DiscreteVariationalParameterizationsDeepV2.py', 'Mutual_Information_Transformer.ipynb', '__pycache__', 'DiscreteVariationalParameterizationsDeepV3.py', 'README.md', 'Mutual_Information_Maximizing_Model.ipynb', 'temp.txt', '.ipynb_checkpoints', '.git', 'QuantumSimulatorDataset.py', 'GibbsSampling.py', '.idea']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch\n",
    "!pip install torchmetrics\n",
    "!pip install qiskit-aer\n",
    "!pip install qiskit\n",
    "!pip install pylatexenc\n",
    "!pip install tqdm\n",
    "!pip install scikit-learn"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "d19Pk1nd54_V",
    "outputId": "fb62d185-755b-4169-968c-217c529563b7",
    "ExecuteTime": {
     "end_time": "2024-07-18T19:45:28.664798Z",
     "start_time": "2024-07-18T19:45:16.293399Z"
    }
   },
   "execution_count": 221,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Collecting torchmetrics\r\n",
      "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchmetrics) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>17.1 in /opt/anaconda3/lib/python3.11/site-packages (from torchmetrics) (23.1)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchmetrics) (2.3.1)\r\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\r\n",
      "  Downloading lightning_utilities-0.11.5-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\r\n",
      "Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m868.8/868.8 kB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading lightning_utilities-0.11.5-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: lightning-utilities, torchmetrics\r\n",
      "Successfully installed lightning-utilities-0.11.5 torchmetrics-1.4.0.post0\r\n",
      "Requirement already satisfied: qiskit-aer in /opt/anaconda3/lib/python3.11/site-packages (0.14.2)\r\n",
      "Requirement already satisfied: qiskit>=0.45.2 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit-aer) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit-aer) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit-aer) (1.11.4)\r\n",
      "Requirement already satisfied: psutil>=5 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit-aer) (5.9.0)\r\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (0.14.2)\r\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (1.12)\r\n",
      "Requirement already satisfied: dill>=0.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (0.3.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (2.8.2)\r\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (5.2.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (4.9.0)\r\n",
      "Requirement already satisfied: symengine>=0.11 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (0.11.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.0->qiskit>=0.45.2->qiskit-aer) (1.16.0)\r\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from stevedore>=3.0.0->qiskit>=0.45.2->qiskit-aer) (6.0.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy>=1.3->qiskit>=0.45.2->qiskit-aer) (1.3.0)\r\n",
      "Requirement already satisfied: qiskit in /opt/anaconda3/lib/python3.11/site-packages (1.1.0)\r\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (0.14.2)\r\n",
      "Requirement already satisfied: numpy<3,>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (1.11.4)\r\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (1.12)\r\n",
      "Requirement already satisfied: dill>=0.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (0.3.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (2.8.2)\r\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (5.2.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (4.9.0)\r\n",
      "Requirement already satisfied: symengine>=0.11 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (0.11.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\r\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from stevedore>=3.0.0->qiskit) (6.0.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy>=1.3->qiskit) (1.3.0)\r\n",
      "Requirement already satisfied: pylatexenc in /opt/anaconda3/lib/python3.11/site-packages (2.10)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (4.65.0)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.clustering import MutualInfoScore\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from QuantumSimulatorDataset import QuantumSimulationDatasetFast, generate_circuit_params"
   ],
   "metadata": {
    "id": "0il2PJTIXtg6",
    "ExecuteTime": {
     "end_time": "2024-07-18T20:06:04.829879Z",
     "start_time": "2024-07-18T20:06:02.590527Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MI and Entropy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def entropy(X):\n",
    "    # Flatten the tensor to 1D\n",
    "    X_flat = X.view(-1)\n",
    "    \n",
    "    # Count the occurrences of each unique value\n",
    "    unique_vals, counts = X_flat.unique(return_counts=True)\n",
    "    probabilities = counts.float() / counts.sum()\n",
    "    entropy = -torch.sum(probabilities * torch.log(probabilities))\n",
    "        \n",
    "    return entropy.item()\n",
    "\n",
    "def mutual_info_loss(X, Y):\n",
    "    # Flatten the tensor to 1D\n",
    "    X_flat = X.view(-1)\n",
    "    Y_flat = Y.view(-1)\n",
    "    \n",
    "    return -mutual_info_score(X_flat, Y_flat)\n",
    "\n",
    "class MutualInformationLoss(nn.Module):\n",
    "    def forward(self, input, target):\n",
    "        X_flat = input.view(-1)\n",
    "        Y_flat = target.view(-1)\n",
    "        \n",
    "        # Compute mutual information\n",
    "        mi = mutual_info_score(X_flat, Y_flat)\n",
    "    \n",
    "        # Convert mutual information to a tensor and return the negative as loss\n",
    "        mi_tensor = torch.tensor(mi, dtype=torch.float32, requires_grad=True).to(input.device)\n",
    "        return -mi_tensor\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T20:23:48.098901Z",
     "start_time": "2024-07-18T20:23:48.082046Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Definition"
   ],
   "metadata": {
    "id": "j87DiZJLfiXR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class QuantumTransformer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_qbits,\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            device,\n",
    "    ):\n",
    "        super(QuantumTransformer, self).__init__()\n",
    "        self.src_emb = nn.Embedding(2, embedding_size)\n",
    "        self.src_position_emb = nn.Embedding(num_qbits, embedding_size)\n",
    "        self.tgt_emb = nn.Embedding(2, embedding_size)\n",
    "        self.tgt_position_emb = nn.Embedding(num_qbits, embedding_size)\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        batch_size, input_dim = src.shape\n",
    "        batch_size, output_dim = tgt.shape\n",
    "        \n",
    "        src_positions = torch.arange(0, input_dim).unsqueeze(0).expand(batch_size, input_dim).to(self.device)\n",
    "        tgt_positions = torch.arange(0, output_dim).unsqueeze(0).expand(batch_size, output_dim).to(self.device)\n",
    "        \n",
    "        embed_src = self.dropout(self.src_emb(src) + self.src_position_emb(src_positions))\n",
    "        embed_tgt = self.dropout(self.tgt_emb(tgt) + self.tgt_position_emb(tgt_positions))\n",
    "        \n",
    "        tgt_mask = self.transformer.generate_square_subsequent_mask(output_dim).to(self.device)\n",
    "        \n",
    "        out = self.transformer(\n",
    "            embed_src.permute(1, 0, 2),  # (S, N, E)\n",
    "            embed_tgt.permute(1, 0, 2),  # (T, N, E)\n",
    "            tgt_mask = tgt_mask\n",
    "        )\n",
    "        out = self.fc_out(out.permute(1, 0, 2))\n",
    "        out = self.sigmoid(out) # (N, S, 1)\n",
    "        \n",
    "        return out.squeeze(-1) # (N, S)\n",
    "    \n",
    "    @staticmethod\n",
    "    def conservation_ones_process(probabilities, num_ones):\n",
    "        sorted_indices = torch.argsort(probabilities, dim=1, descending=True)\n",
    "        threshold_output = torch.zeros_like(probabilities)\n",
    "    \n",
    "        for j in range(probabilities.size(0)):\n",
    "            threshold_output[j, sorted_indices[j, : num_ones]] = 1\n",
    "        \n",
    "        return threshold_output\n",
    "        "
   ],
   "metadata": {
    "id": "QkPRHQTkflC-",
    "ExecuteTime": {
     "end_time": "2024-07-19T01:59:51.099266Z",
     "start_time": "2024-07-19T01:59:51.096369Z"
    }
   },
   "execution_count": 245,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Initialization and Training"
   ],
   "metadata": {
    "id": "UKRswzQ1BmyZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Version 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "#Hyperparameters\n",
    "num_iterations = 10000\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "binary_vocab_size = 2\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dropout = 0.1\n",
    "qbits = 12\n",
    "forward_expansion = 4\n",
    "inverse_density = 3\n",
    "num_qbits = 12\n",
    "num_ones = int(num_qbits/inverse_density)\n",
    "num_final_per_initial = 4\n",
    "\n",
    "model = QuantumTransformer(qbits, embedding_size, num_heads, num_encoder_layers, num_decoder_layers, forward_expansion, dropout, device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "params = generate_circuit_params(0,num_qbits)\n",
    "#params = generate_circuit_params(file_name = directory_path + 'dense_small.param')\n",
    "dataset = QuantumSimulationDatasetFast(params, batch_size, num_final_per_initial, device, inverse_density=inverse_density)\n",
    "print('Device:', device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJHfp3CDA-0N",
    "outputId": "1335a2d1-b855-436a-b96c-32f012c5a772",
    "ExecuteTime": {
     "end_time": "2024-07-19T02:22:32.893064Z",
     "start_time": "2024-07-19T02:22:32.643845Z"
    }
   },
   "execution_count": 257,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "| Iteration 0  > Loss(Y,ȳ): 0.73320  I(X,ȳ): 0.00021  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 10  > Loss(Y,ȳ): 0.62291  I(X,ȳ): 0.00088  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 20  > Loss(Y,ȳ): 0.62973  I(X,ȳ): 0.00026  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 30  > Loss(Y,ȳ): 0.63207  I(X,ȳ): 0.00041  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 40  > Loss(Y,ȳ): 0.63606  I(X,ȳ): 0.00038  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 50  > Loss(Y,ȳ): 0.64274  I(X,ȳ): 0.00001  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 60  > Loss(Y,ȳ): 0.67739  I(X,ȳ): 0.02324  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 70  > Loss(Y,ȳ): 0.64135  I(X,ȳ): 0.01087  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 80  > Loss(Y,ȳ): 0.65851  I(X,ȳ): 0.00018  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 90  > Loss(Y,ȳ): 0.63860  I(X,ȳ): 0.00222  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 100  > Loss(Y,ȳ): 0.61351  I(X,ȳ): 0.00067  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 110  > Loss(Y,ȳ): 0.65196  I(X,ȳ): 0.00026  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 120  > Loss(Y,ȳ): 0.63373  I(X,ȳ): 0.00041  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 130  > Loss(Y,ȳ): 0.64864  I(X,ȳ): 0.00103  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 140  > Loss(Y,ȳ): 0.65117  I(X,ȳ): 0.00265  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 150  > Loss(Y,ȳ): 0.65883  I(X,ȳ): 0.00434  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 160  > Loss(Y,ȳ): 0.61765  I(X,ȳ): 0.00061  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 170  > Loss(Y,ȳ): 0.65110  I(X,ȳ): 0.00214  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 180  > Loss(Y,ȳ): 0.64649  I(X,ȳ): 0.00249  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 190  > Loss(Y,ȳ): 0.64692  I(X,ȳ): 0.00538  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 200  > Loss(Y,ȳ): 0.64299  I(X,ȳ): 0.00305  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 210  > Loss(Y,ȳ): 0.63373  I(X,ȳ): 0.00026  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 220  > Loss(Y,ȳ): 0.65387  I(X,ȳ): 0.00038  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 230  > Loss(Y,ȳ): 0.65988  I(X,ȳ): 0.00002  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 240  > Loss(Y,ȳ): 0.64420  I(X,ȳ): 0.00222  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 250  > Loss(Y,ȳ): 0.64711  I(X,ȳ): 0.00003  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 260  > Loss(Y,ȳ): 0.65215  I(X,ȳ): 0.00087  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 270  > Loss(Y,ȳ): 0.61342  I(X,ȳ): 0.00197  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 280  > Loss(Y,ȳ): 0.63834  I(X,ȳ): 0.00038  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 290  > Loss(Y,ȳ): 0.63665  I(X,ȳ): 0.00038  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 300  > Loss(Y,ȳ): 0.64068  I(X,ȳ): 0.00080  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 310  > Loss(Y,ȳ): 0.65724  I(X,ȳ): 0.00287  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 320  > Loss(Y,ȳ): 0.63770  I(X,ȳ): 0.00000  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 330  > Loss(Y,ȳ): 0.63575  I(X,ȳ): 0.00005  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 340  > Loss(Y,ȳ): 0.64143  I(X,ȳ): 0.00214  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 350  > Loss(Y,ȳ): 0.64931  I(X,ȳ): 0.00087  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 360  > Loss(Y,ȳ): 0.64337  I(X,ȳ): 0.00021  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 370  > Loss(Y,ȳ): 0.62613  I(X,ȳ): 0.00024  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 380  > Loss(Y,ȳ): 0.65354  I(X,ȳ): 0.00009  I(X,Y): 0.00000  H(X): 0.63651\n",
      "| Iteration 390  > Loss(Y,ȳ): 0.63120  I(X,ȳ): 0.00181  I(X,Y): 0.00000  H(X): 0.63651\n"
     ]
    }
   ],
   "source": [
    "BCELoss_array = []\n",
    "MI_array = []\n",
    "\n",
    "print('Training')\n",
    "model.train()\n",
    "for idx, (initial_state, final_state) in enumerate(dataset):\n",
    "    initial_state, final_state = initial_state.to(device).long(), final_state.to(device).long()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    out = model(initial_state, final_state[:, :-1])    \n",
    "    final_state = final_state[:, 1:] # Reshape final_state to  (batch_size * sequence_length[:,1:])\n",
    "\n",
    "    loss = criterion(out, final_state.float())\n",
    "    predictions = QuantumTransformer.conservation_ones_process(out, num_ones)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.grad is not None:\n",
    "    #         print(f\"Gradients for {name}: {param.grad}\")\n",
    "    optimizer.step()\n",
    "            \n",
    "    mutual_info = mutual_info_score(final_state.reshape(-1), predictions.reshape(-1))\n",
    "    #expected_mutual_info = mutual_info_score(initial_state.view(-1), final_state.view(-1))\n",
    "    initial_entropy = entropy(initial_state)\n",
    "    expected_mutual_info = 0\n",
    "    \n",
    "    BCELoss_array.append(loss.item())\n",
    "    MI_array.append(mutual_info)\n",
    "\n",
    "    if idx % 10 == 0:\n",
    "        print('| Iteration', idx, ' > Loss(Y,ȳ):', f\"{loss:,.5f}\", \n",
    "              ' I(X,ȳ):', f\"{mutual_info:,.5f}\",\n",
    "              ' I(X,Y):', f\"{expected_mutual_info:,.5f}\",\n",
    "              ' H(X):', f\"{initial_entropy:,.5f}\")\n",
    "\n",
    "    if idx > num_iterations:\n",
    "        print('Training Terminated')\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-19T02:22:34.712519Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "BCEloss_np = np.array(BCELoss_array)\n",
    "MI_np = np.array(MI_array)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(MI_np)+1), MI_np, marker='o')\n",
    "plt.plot(range(1, len(BCEloss_np)+1), BCEloss_np, marker='x')\n",
    "\n",
    "plt.title('Training BCW Loss and MI')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss and MI')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "twCAozYjS4J9",
    "ExecuteTime": {
     "start_time": "2024-07-18T20:58:16.017016Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "total_loss = 0.0\n",
    "predictions = []\n",
    "given = []\n",
    "actual = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, targets) in enumerate(tqdm(test_loader, desc=f'Epoch {epoch+1}/{epochs}')):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = model(inputs.long(), targets.long())\n",
    "        loss = criterion(outputs, targets.float())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        for i in range(len(inputs)):\n",
    "            predictions.append(outputs[i].tolist())\n",
    "            given.append(inputs[i].tolist())\n",
    "            actual.append(targets[i].tolist())\n",
    "\n",
    "    avg_test_loss = total_loss / len(test_loader)\n",
    "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "# Save the model and predictions\n",
    "torch.save(model.state_dict(), 'quantum_transformer_model.pth')\n",
    "preds = {\n",
    "    'Initial_States': given,\n",
    "    'Final_State_Pred': predictions,\n",
    "    'Final_States': actual\n",
    "}\n",
    "final_df = pd.DataFrame(preds)\n",
    "final_df.head()"
   ],
   "metadata": {
    "id": "d2BA8KDbP0E5"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
