{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# File Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d20f279371c8dd95"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dense_small.param', '.DS_Store', 'quantum_experiments', 'DiscreteVariationalParameterizationsDeepV2.py', 'Attention_Psuedocode.ipynb', 'Mutual_Information_Transformer.ipynb', '__pycache__', 'DiscreteVariationalParameterizationsDeepV3.py', 'README.md', 'Mutual_Information_Maximizing_Model.ipynb', 'temp.txt', '.ipynb_checkpoints', '.git', 'QuantumSimulatorDataset.py', 'GibbsSampling.py', 'Mutual_Information_VAETransformer.ipynb', '.idea']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "directory_path = ''\n",
    "\n",
    "#from google.colab import drive\n",
    "#import sys\n",
    "#drive.mount('/content/drive')\n",
    "#directory_path = '/content/drive/MyDrive/Quantum/'\n",
    "#sys.path.append('/content/drive/MyDrive/Quantum')\n",
    "# print(os.listdir(directory_path))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T17:32:55.785640Z",
     "start_time": "2024-08-20T17:32:55.778127Z"
    }
   },
   "id": "341477d29908ffde"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: torchmetrics in /opt/anaconda3/lib/python3.11/site-packages (1.4.0.post0)\r\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchmetrics) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>17.1 in /opt/anaconda3/lib/python3.11/site-packages (from torchmetrics) (23.1)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchmetrics) (2.3.1)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchmetrics) (0.11.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\r\n",
      "Requirement already satisfied: qiskit-aer in /opt/anaconda3/lib/python3.11/site-packages (0.14.2)\r\n",
      "Requirement already satisfied: qiskit>=0.45.2 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit-aer) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit-aer) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit-aer) (1.11.4)\r\n",
      "Requirement already satisfied: psutil>=5 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit-aer) (5.9.0)\r\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (0.14.2)\r\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (1.12)\r\n",
      "Requirement already satisfied: dill>=0.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (0.3.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (2.8.2)\r\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (5.2.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (4.9.0)\r\n",
      "Requirement already satisfied: symengine>=0.11 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit>=0.45.2->qiskit-aer) (0.11.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.0->qiskit>=0.45.2->qiskit-aer) (1.16.0)\r\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from stevedore>=3.0.0->qiskit>=0.45.2->qiskit-aer) (6.0.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy>=1.3->qiskit>=0.45.2->qiskit-aer) (1.3.0)\r\n",
      "Requirement already satisfied: qiskit in /opt/anaconda3/lib/python3.11/site-packages (1.1.0)\r\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (0.14.2)\r\n",
      "Requirement already satisfied: numpy<3,>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (1.11.4)\r\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (1.12)\r\n",
      "Requirement already satisfied: dill>=0.3 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (0.3.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (2.8.2)\r\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (5.2.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (4.9.0)\r\n",
      "Requirement already satisfied: symengine>=0.11 in /opt/anaconda3/lib/python3.11/site-packages (from qiskit) (0.11.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\r\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from stevedore>=3.0.0->qiskit) (6.0.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy>=1.3->qiskit) (1.3.0)\r\n",
      "Requirement already satisfied: pylatexenc in /opt/anaconda3/lib/python3.11/site-packages (2.10)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (4.65.0)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchmetrics\n",
    "!pip install qiskit-aer\n",
    "!pip install qiskit\n",
    "!pip install pylatexenc\n",
    "!pip install tqdm\n",
    "!pip install scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T17:33:09.210710Z",
     "start_time": "2024-08-20T17:32:58.116797Z"
    }
   },
   "id": "c92d4e99377dbfd"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.clustering import MutualInfoScore\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from QuantumSimulatorDataset import QuantumSimulationDatasetFast, generate_circuit_params\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T17:37:37.743452Z",
     "start_time": "2024-08-20T17:37:28.825560Z"
    }
   },
   "id": "b1965ee767ba8520"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d17a39d7d79ef03"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def calc_binary_accuracy(predictions, targets):\n",
    "    correct = (predictions == targets).float().sum()\n",
    "    accuracy = correct / targets.numel()\n",
    "    return accuracy.item()\n",
    "\n",
    "def entropy(X):\n",
    "    # Flatten the tensor to 1D\n",
    "    X_flat = X.view(-1)\n",
    "    \n",
    "    # Count the occurrences of each unique value\n",
    "    unique_vals, counts = X_flat.unique(return_counts=True)\n",
    "    probabilities = counts.float() / counts.sum()\n",
    "    entropy = -torch.sum(probabilities * torch.log(probabilities))\n",
    "        \n",
    "    return entropy.item()\n",
    "\n",
    "def MutualInformationLoss(pred, target):\n",
    "    X_flat = pred.view(-1)\n",
    "    Y_flat = target.view(-1)\n",
    "    \n",
    "    # Compute mutual information\n",
    "    mi = mutual_info_score(X_flat.detach(), Y_flat.detach())\n",
    "\n",
    "    # Convert mutual information to a tensor and return the negative as loss\n",
    "    mi_tensor = torch.tensor(mi, dtype=torch.float32, requires_grad=True).to(pred.device)\n",
    "    return -mi_tensor\n",
    "    \n",
    "def KL_divergence(mu1, logvar1, mu2, logvar2):\n",
    "    var1 = torch.exp(logvar1)\n",
    "    var2 = torch.exp(logvar2)\n",
    "    \n",
    "    # KL divergence between two gaussian distributions\n",
    "    kl_div = 0.5 * (torch.log(var2 / var1) - 1 + (var1 / var2) + (mu1 - mu2).pow(2) / var2).sum(dim=-1)\n",
    "    \n",
    "    return kl_div.mean()\n",
    "    \n",
    "def lighten(color, amount=0.3):\n",
    "    c = color\n",
    "    c = mcolors.to_rgb(c)\n",
    "    white = np.array([1.0, 1.0, 1.0])\n",
    "    new_color = (1.0 - amount) * np.array(c) + amount * white\n",
    "    return tuple(new_color)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T18:38:09.436091Z",
     "start_time": "2024-08-20T18:38:09.407932Z"
    }
   },
   "id": "d9f1252e196b2feb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VAETransformer Definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49268227c3a02ce6"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-20T20:20:18.009817Z",
     "start_time": "2024-08-20T20:20:18.001439Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        mu = self.fc2_mu(h)\n",
    "        logvar = self.fc2_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "class LatentTransformer(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim):\n",
    "        super(LatentTransformer, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, latent_dim)\n",
    "    \n",
    "    def forward(self, z_init):\n",
    "        temp = F.relu(self.fc1(z_init))\n",
    "        temp = F.relu(self.fc2(temp))\n",
    "        return F.relu(self.fc3(temp))\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, z_final):\n",
    "        h = F.relu(self.fc1(z_final))\n",
    "        return torch.sigmoid(self.fc2(h))\n",
    "\n",
    "class VAETransformer(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, output_dim, num_ones, hidden_dim=128):\n",
    "        super(VAETransformer, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, latent_dim, hidden_dim)\n",
    "        self.latent_transformer = LatentTransformer(latent_dim, hidden_dim)\n",
    "        self.decoder = Decoder(latent_dim, output_dim, hidden_dim)\n",
    "        self.num_ones = num_ones\n",
    "        self.hidden_dim = hidden_dim\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x_init):\n",
    "        mu, logvar = self.encoder(x_init)\n",
    "        z_init = self.reparameterize(mu, logvar)\n",
    "        z_final = self.latent_transformer(z_init)\n",
    "        x_final = self.decoder(z_final)\n",
    "        return x_final, z_final, mu, logvar\n",
    "\n",
    "    def conservation_ones_process(self, probabilities):\n",
    "        sorted_indices = torch.argsort(probabilities, dim=1, descending=True)\n",
    "        threshold_output = torch.zeros_like(probabilities)\n",
    "    \n",
    "        for j in range(probabilities.size(0)):\n",
    "            threshold_output[j, sorted_indices[j, : self.num_ones]] = 1\n",
    "        \n",
    "        return threshold_output"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "945173c3667f9b39"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def train_VAETransformer(num_qbits, num_final_per_initial, inverse_density, num_ones, batch_size, circuit_length,\n",
    "                         latent_dim, hidden_dim, dropout, learning_rate, num_steps, device):\n",
    "\n",
    "    params = generate_circuit_params(circuit_length,num_qbits)\n",
    "    #params = generate_circuit_params(file_name = directory_path + 'dense_small.param')\n",
    "    dataset = QuantumSimulationDatasetFast(params, batch_size, num_final_per_initial, device, inverse_density=inverse_density)\n",
    "        \n",
    "    # Model\n",
    "    model = (VAETransformer(num_qbits, latent_dim, num_qbits, num_ones, hidden_dim)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "    # criterion = KL_divergence\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_Loss_array = []\n",
    "    train_BAcc_array = []\n",
    "    train_MI_array = []\n",
    "    expected_mutual_info_array = []\n",
    "    upperBound = 0.0\n",
    "    \n",
    "    print('Training With Latent Dimension ', f\"{latent_dim:02}\", ' for ', num_steps, ' iterations:')\n",
    "    for idx, (initial_state, final_state) in enumerate(dataset):\n",
    "        model.train()    \n",
    "        initial_state, final_state = initial_state.to(device), final_state.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output, pred_y_bar, mu1, logvar1 = model(initial_state)\n",
    "        \n",
    "        mu2, logvar2 = model.encoder(final_state)\n",
    "        actual_y_bar = model.reparameterize(mu2, logvar2)\n",
    "                \n",
    "        loss = criterion(output, final_state.float())   \n",
    "        # loss = criterion(mu1, logvar1, mu2, logvar2)\n",
    "                \n",
    "        prediction = model.conservation_ones_process(output)\n",
    "        BAccuracy = calc_binary_accuracy(final_state, prediction)\n",
    "            \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Adjust max_norm as needed\n",
    "        optimizer.step()\n",
    "        \n",
    "        mutual_info = mutual_info_score(initial_state.cpu().reshape(-1), prediction.cpu().reshape(-1))\n",
    "        expected_mutual_info = mutual_info_score(initial_state.cpu().reshape(-1), final_state.cpu().reshape(-1))\n",
    "        \n",
    "        train_Loss_array.append(loss.item())\n",
    "        train_BAcc_array.append(BAccuracy)\n",
    "        train_MI_array.append(mutual_info)\n",
    "        expected_mutual_info_array.append(expected_mutual_info)\n",
    "        if idx == 0:\n",
    "            upperBound = entropy(initial_state)\n",
    "        if idx % 10 == 0:\n",
    "            print(' | Iteration', f\"{idx:04}\", ' > Loss(ȳ,ȳ\\'):', f\"{loss:,.9f}\",\n",
    "                  ' BAcc:', f\"{BAccuracy:,.5f}\",\n",
    "                  ' I(X,Y\\'):', f\"{mutual_info:,.5f}\",\n",
    "                  ' I(X,Y):', f\"{expected_mutual_info:,.5f}\")\n",
    "            \n",
    "        if idx == (num_steps-1):\n",
    "            break\n",
    "            \n",
    "    return train_Loss_array, train_BAcc_array, train_MI_array, expected_mutual_info_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T20:23:18.981313Z",
     "start_time": "2024-08-20T20:23:18.973116Z"
    }
   },
   "id": "1b89372dc5fe64bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cf125fa04880164"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(all_loss_arrays, all_acc_arrays, circuit_length, num_qbits, latent_spaces):\n",
    "    colors = ['navy', 'orange', 'navy', 'navy', 'navy', 'navy']\n",
    "    num_plots = len(all_loss_arrays)\n",
    "    num_cols = 3  # Number of columns for the grid\n",
    "    num_rows = (num_plots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "    axes = axes.flatten()  # Flatten the array of axes for easy iteration\n",
    "\n",
    "    for i, (train_Loss, train_BAcc) in enumerate(zip(all_loss_arrays, all_acc_arrays)):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Array manipulation\n",
    "        train_Loss_array = np.array(train_Loss)\n",
    "        train_BAcc_array = np.array(train_BAcc)\n",
    "        window_size = 300\n",
    "        smoothed_train_BCELoss = np.convolve(train_Loss_array, np.ones(window_size)/window_size, mode='valid')\n",
    "        smoothed_train_BAcc = np.convolve(train_BAcc_array, np.ones(window_size)/window_size, mode='valid')\n",
    "        epochs = np.arange(1, len(smoothed_train_BCELoss) + 1)\n",
    "        \n",
    "        # Plotting\n",
    "        label1 = str(latent_spaces[i]) + ' Loss, Accuracy'\n",
    "        ax.plot(epochs, smoothed_train_BCELoss, color=colors[0], linestyle='-', linewidth=1, label='BCELoss')\n",
    "        ax.plot(epochs, smoothed_train_BAcc, color=colors[1], linestyle='-', linewidth=1, label='Accuracy')\n",
    "        \n",
    "        # Style\n",
    "        title = '(Latent Space ' + str(latent_spaces[i]) + ')'\n",
    "        ax.set_title(title, fontsize=10)        \n",
    "        ax.set_xlabel('Epoch', fontsize=8)\n",
    "        ax.set_ylabel('Metric Values', fontsize=8)\n",
    "        ax.legend(loc='best', fontsize=8)\n",
    "        ax.set_ylim((0,1.0))\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    fig.suptitle('VAETransformer: Loss and Accuracy', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T17:49:19.570545Z",
     "start_time": "2024-08-20T17:49:19.567172Z"
    }
   },
   "id": "f2e41ceeba440761"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def plot_MI(all_mi_arrays, all_expected_mi_arrays, circuit_length, num_qbits, latent_spaces):\n",
    "    colors = ['navy', 'navy', 'navy', 'navy', 'navy', 'navy']\n",
    "    num_plots = len(all_mi_arrays)\n",
    "    num_cols = 3  # Set number of columns for the grid\n",
    "    num_rows = (num_plots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "    axes = axes.flatten()  # Flatten the array of axes for easy iteration\n",
    "\n",
    "    for i, (train_MI_array, expected_mutual_info_array) in enumerate(zip(all_mi_arrays, all_expected_mi_arrays)):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Array manipulation\n",
    "        train_MI_array = np.array(train_MI_array)\n",
    "        expected_MI_array = np.array(expected_mutual_info_array)\n",
    "        MI_difference = expected_MI_array - train_MI_array\n",
    "        window_size = 300\n",
    "        smoothed_train_MI = np.convolve(train_MI_array, np.ones(window_size)/window_size, mode='valid')\n",
    "        smoothed_expected_MI = np.convolve(expected_MI_array, np.ones(window_size)/window_size, mode='valid')\n",
    "        smoothed_difference_MI = np.convolve(MI_difference, np.ones(window_size)/window_size, mode='valid')\n",
    "        epochs = np.arange(1, len(smoothed_train_MI) + 1)\n",
    "        epochs2 = np.arange(1, len(smoothed_difference_MI) + 1)\n",
    "\n",
    "        # Plotting\n",
    "        MI_label1 = str(latent_spaces[i]) + ' I(X,Y) - I(X,ȳ)'\n",
    "        ax.plot(epochs, smoothed_train_MI, color=colors[i], linestyle='-', linewidth=1.5, label=MI_label1)\n",
    "        ax.plot(epochs, smoothed_expected_MI, color=colors[i], linestyle='-', linewidth=1.5)\n",
    "        ax.fill_between(epochs, y1=smoothed_train_MI, y2=smoothed_expected_MI, color=colors[i], alpha=0.5)\n",
    "        # ax.plot(epochs2, smoothed_difference_MI, color=colors[i], linestyle='-', linewidth=1, label=MI_label1)\n",
    "\n",
    "        # Style\n",
    "        title = '(Latent Space ' + str(latent_spaces[i]) + ')'\n",
    "        ax.set_title(title, fontsize=10)\n",
    "        subtitle = str(num_qbits) + ' Qubit Circuit of length: ' + str(circuit_length) + ' | Version 1'\n",
    "        ax.set_xlabel('Epoch', fontsize=8)\n",
    "        ax.set_ylabel('Metric Values', fontsize=8)\n",
    "        \n",
    "        ax.legend(loc='best', fontsize=8)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    fig.suptitle('VAETransformer: Mutual Information', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T17:49:20.104295Z",
     "start_time": "2024-08-20T17:49:20.098280Z"
    }
   },
   "id": "e3a93ef09f8b38e9"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Training With Latent Dimension  04  for  5000  iterations:\n",
      " | Iteration 0000  > Loss(ȳ,ȳ'): 0.687506735  BAcc: 0.55208  I(X,Y'): 0.00003  I(X,Y): 0.36737\n",
      " | Iteration 0010  > Loss(ȳ,ȳ'): 0.638310254  BAcc: 0.56250  I(X,Y'): 0.00012  I(X,Y): 0.39314\n",
      " | Iteration 0020  > Loss(ȳ,ȳ'): 0.643259287  BAcc: 0.55729  I(X,Y'): 0.00005  I(X,Y): 0.32584\n",
      " | Iteration 0030  > Loss(ȳ,ȳ'): 0.629884899  BAcc: 0.58073  I(X,Y'): 0.00120  I(X,Y): 0.33728\n",
      " | Iteration 0040  > Loss(ȳ,ȳ'): 0.608688653  BAcc: 0.61458  I(X,Y'): 0.00317  I(X,Y): 0.47396\n",
      " | Iteration 0050  > Loss(ȳ,ȳ'): 0.594567955  BAcc: 0.67448  I(X,Y'): 0.01583  I(X,Y): 0.36117\n",
      " | Iteration 0060  > Loss(ȳ,ȳ'): 0.579452693  BAcc: 0.65365  I(X,Y'): 0.02385  I(X,Y): 0.38654\n",
      " | Iteration 0070  > Loss(ȳ,ȳ'): 0.585844517  BAcc: 0.65625  I(X,Y'): 0.01384  I(X,Y): 0.34905\n",
      " | Iteration 0080  > Loss(ȳ,ȳ'): 0.606739819  BAcc: 0.65625  I(X,Y'): 0.02512  I(X,Y): 0.45021\n",
      " | Iteration 0090  > Loss(ȳ,ȳ'): 0.598489106  BAcc: 0.61719  I(X,Y'): 0.00946  I(X,Y): 0.31472\n",
      " | Iteration 0100  > Loss(ȳ,ȳ'): 0.574758053  BAcc: 0.63542  I(X,Y'): 0.01583  I(X,Y): 0.42066\n",
      " | Iteration 0110  > Loss(ȳ,ȳ'): 0.585160375  BAcc: 0.63542  I(X,Y'): 0.01583  I(X,Y): 0.44261\n",
      " | Iteration 0120  > Loss(ȳ,ȳ'): 0.595666587  BAcc: 0.61458  I(X,Y'): 0.00365  I(X,Y): 0.36737\n",
      " | Iteration 0130  > Loss(ȳ,ȳ'): 0.577379167  BAcc: 0.58854  I(X,Y'): 0.00416  I(X,Y): 0.38654\n",
      " | Iteration 0140  > Loss(ȳ,ȳ'): 0.578590214  BAcc: 0.61458  I(X,Y'): 0.00868  I(X,Y): 0.37366\n",
      " | Iteration 0150  > Loss(ȳ,ȳ'): 0.581183612  BAcc: 0.57292  I(X,Y'): 0.00194  I(X,Y): 0.39314\n",
      " | Iteration 0160  > Loss(ȳ,ȳ'): 0.561689317  BAcc: 0.64323  I(X,Y'): 0.00946  I(X,Y): 0.37366\n",
      " | Iteration 0170  > Loss(ȳ,ȳ'): 0.580549777  BAcc: 0.58594  I(X,Y'): 0.00365  I(X,Y): 0.30927\n",
      " | Iteration 0180  > Loss(ȳ,ȳ'): 0.553489804  BAcc: 0.65625  I(X,Y'): 0.02512  I(X,Y): 0.42784\n",
      " | Iteration 0190  > Loss(ȳ,ȳ'): 0.564243972  BAcc: 0.59375  I(X,Y'): 0.00365  I(X,Y): 0.36117\n",
      " | Iteration 0200  > Loss(ȳ,ȳ'): 0.553600848  BAcc: 0.68490  I(X,Y'): 0.03657  I(X,Y): 0.39985\n",
      " | Iteration 0210  > Loss(ȳ,ȳ'): 0.550981879  BAcc: 0.65625  I(X,Y'): 0.02512  I(X,Y): 0.39314\n",
      " | Iteration 0220  > Loss(ȳ,ȳ'): 0.543060541  BAcc: 0.68229  I(X,Y'): 0.04311  I(X,Y): 0.47396\n",
      " | Iteration 0230  > Loss(ȳ,ȳ'): 0.539258420  BAcc: 0.63542  I(X,Y'): 0.01583  I(X,Y): 0.32584\n",
      " | Iteration 0240  > Loss(ȳ,ȳ'): 0.536473095  BAcc: 0.68750  I(X,Y'): 0.05396  I(X,Y): 0.33728\n",
      " | Iteration 0250  > Loss(ȳ,ȳ'): 0.549846530  BAcc: 0.61458  I(X,Y'): 0.00868  I(X,Y): 0.40667\n",
      " | Iteration 0260  > Loss(ȳ,ȳ'): 0.543517530  BAcc: 0.61458  I(X,Y'): 0.01199  I(X,Y): 0.34905\n",
      " | Iteration 0270  > Loss(ȳ,ȳ'): 0.519996166  BAcc: 0.69792  I(X,Y'): 0.03815  I(X,Y): 0.39985\n",
      " | Iteration 0280  > Loss(ȳ,ȳ'): 0.531536818  BAcc: 0.64844  I(X,Y'): 0.01796  I(X,Y): 0.38654\n",
      " | Iteration 0290  > Loss(ȳ,ȳ'): 0.550370455  BAcc: 0.59375  I(X,Y'): 0.01199  I(X,Y): 0.33728\n",
      " | Iteration 0300  > Loss(ȳ,ȳ'): 0.504119337  BAcc: 0.72917  I(X,Y'): 0.05786  I(X,Y): 0.38654\n",
      " | Iteration 0310  > Loss(ȳ,ȳ'): 0.516353309  BAcc: 0.65104  I(X,Y'): 0.04311  I(X,Y): 0.28312\n",
      " | Iteration 0320  > Loss(ȳ,ȳ'): 0.504387379  BAcc: 0.68750  I(X,Y'): 0.02512  I(X,Y): 0.38005\n",
      " | Iteration 0330  > Loss(ȳ,ȳ'): 0.530883908  BAcc: 0.64583  I(X,Y'): 0.03058  I(X,Y): 0.38005\n",
      " | Iteration 0340  > Loss(ȳ,ȳ'): 0.491358072  BAcc: 0.69792  I(X,Y'): 0.05021  I(X,Y): 0.45021\n",
      " | Iteration 0350  > Loss(ȳ,ȳ'): 0.516651213  BAcc: 0.69792  I(X,Y'): 0.04311  I(X,Y): 0.36737\n",
      " | Iteration 0360  > Loss(ȳ,ȳ'): 0.518901646  BAcc: 0.65365  I(X,Y'): 0.02512  I(X,Y): 0.42784\n",
      " | Iteration 0370  > Loss(ȳ,ȳ'): 0.497924805  BAcc: 0.71354  I(X,Y'): 0.06609  I(X,Y): 0.38654\n",
      " | Iteration 0380  > Loss(ȳ,ȳ'): 0.503071845  BAcc: 0.71875  I(X,Y'): 0.06609  I(X,Y): 0.36737\n",
      " | Iteration 0390  > Loss(ȳ,ȳ'): 0.464729756  BAcc: 0.71354  I(X,Y'): 0.06609  I(X,Y): 0.38654\n",
      " | Iteration 0400  > Loss(ȳ,ȳ'): 0.473342091  BAcc: 0.72917  I(X,Y'): 0.07489  I(X,Y): 0.42066\n",
      " | Iteration 0410  > Loss(ȳ,ȳ'): 0.494740695  BAcc: 0.68490  I(X,Y'): 0.04142  I(X,Y): 0.40667\n",
      " | Iteration 0420  > Loss(ȳ,ȳ'): 0.481008142  BAcc: 0.67969  I(X,Y'): 0.04311  I(X,Y): 0.34312\n",
      " | Iteration 0430  > Loss(ȳ,ȳ'): 0.475595325  BAcc: 0.69010  I(X,Y'): 0.02778  I(X,Y): 0.42066\n",
      " | Iteration 0440  > Loss(ȳ,ȳ'): 0.510682940  BAcc: 0.66667  I(X,Y'): 0.02021  I(X,Y): 0.37366\n",
      " | Iteration 0450  > Loss(ȳ,ȳ'): 0.475354105  BAcc: 0.73177  I(X,Y'): 0.08428  I(X,Y): 0.37366\n",
      " | Iteration 0460  > Loss(ȳ,ȳ'): 0.488966107  BAcc: 0.67969  I(X,Y'): 0.05021  I(X,Y): 0.37366\n",
      " | Iteration 0470  > Loss(ȳ,ȳ'): 0.501348555  BAcc: 0.66667  I(X,Y'): 0.02512  I(X,Y): 0.32024\n",
      " | Iteration 0480  > Loss(ȳ,ȳ'): 0.490402132  BAcc: 0.65104  I(X,Y'): 0.02139  I(X,Y): 0.39314\n",
      " | Iteration 0490  > Loss(ȳ,ȳ'): 0.487327904  BAcc: 0.62760  I(X,Y'): 0.02512  I(X,Y): 0.32024\n",
      " | Iteration 0500  > Loss(ȳ,ȳ'): 0.495630383  BAcc: 0.67188  I(X,Y'): 0.03350  I(X,Y): 0.41360\n",
      " | Iteration 0510  > Loss(ȳ,ȳ'): 0.500727832  BAcc: 0.68229  I(X,Y'): 0.04838  I(X,Y): 0.32024\n",
      " | Iteration 0520  > Loss(ȳ,ȳ'): 0.470617980  BAcc: 0.71875  I(X,Y'): 0.06609  I(X,Y): 0.46588\n",
      " | Iteration 0530  > Loss(ȳ,ȳ'): 0.478855252  BAcc: 0.71875  I(X,Y'): 0.06609  I(X,Y): 0.33728\n",
      " | Iteration 0540  > Loss(ȳ,ȳ'): 0.497644186  BAcc: 0.66667  I(X,Y'): 0.04311  I(X,Y): 0.36737\n",
      " | Iteration 0550  > Loss(ȳ,ȳ'): 0.478424400  BAcc: 0.69792  I(X,Y'): 0.09427  I(X,Y): 0.28821\n",
      " | Iteration 0560  > Loss(ȳ,ȳ'): 0.481669456  BAcc: 0.67708  I(X,Y'): 0.04311  I(X,Y): 0.41360\n",
      " | Iteration 0570  > Loss(ȳ,ȳ'): 0.465404838  BAcc: 0.72917  I(X,Y'): 0.06609  I(X,Y): 0.39314\n",
      " | Iteration 0580  > Loss(ȳ,ȳ'): 0.479075223  BAcc: 0.69792  I(X,Y'): 0.04311  I(X,Y): 0.41360\n",
      " | Iteration 0590  > Loss(ȳ,ȳ'): 0.487189144  BAcc: 0.67448  I(X,Y'): 0.04311  I(X,Y): 0.42784\n",
      " | Iteration 0600  > Loss(ȳ,ȳ'): 0.466683656  BAcc: 0.72396  I(X,Y'): 0.04311  I(X,Y): 0.32024\n",
      " | Iteration 0610  > Loss(ȳ,ȳ'): 0.467788130  BAcc: 0.71354  I(X,Y'): 0.05786  I(X,Y): 0.45796\n",
      " | Iteration 0620  > Loss(ȳ,ȳ'): 0.466065735  BAcc: 0.70052  I(X,Y'): 0.07489  I(X,Y): 0.38005\n",
      " | Iteration 0630  > Loss(ȳ,ȳ'): 0.480726212  BAcc: 0.72917  I(X,Y'): 0.08428  I(X,Y): 0.39314\n",
      " | Iteration 0640  > Loss(ȳ,ȳ'): 0.472751945  BAcc: 0.71875  I(X,Y'): 0.04838  I(X,Y): 0.28821\n",
      " | Iteration 0650  > Loss(ȳ,ȳ'): 0.436541408  BAcc: 0.74740  I(X,Y'): 0.04311  I(X,Y): 0.33728\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m all_expected_mi_arrays \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (latent_space) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(latent_spaces):\n\u001B[0;32m---> 32\u001B[0m     temp_loss, temp_acc, temp_mi, temp_exmi \u001B[38;5;241m=\u001B[39m train_VAETransformer(\u001B[38;5;241m*\u001B[39mdataset_hyperparams, latent_space, \u001B[38;5;241m*\u001B[39mmodel_hyperparams, device)\n\u001B[1;32m     33\u001B[0m     all_loss_arrays\u001B[38;5;241m.\u001B[39mappend(temp_loss)\n\u001B[1;32m     34\u001B[0m     all_acc_arrays\u001B[38;5;241m.\u001B[39mappend(temp_acc)\n",
      "Cell \u001B[0;32mIn[76], line 22\u001B[0m, in \u001B[0;36mtrain_VAETransformer\u001B[0;34m(num_qbits, num_final_per_initial, inverse_density, num_ones, batch_size, circuit_length, latent_dim, hidden_dim, dropout, learning_rate, num_steps, device)\u001B[0m\n\u001B[1;32m     19\u001B[0m upperBound \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining With Latent Dimension \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlatent_dim\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m02\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for \u001B[39m\u001B[38;5;124m'\u001B[39m, num_steps, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m iterations:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, (initial_state, final_state) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataset):\n\u001B[1;32m     23\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()    \n\u001B[1;32m     24\u001B[0m     initial_state, final_state \u001B[38;5;241m=\u001B[39m initial_state\u001B[38;5;241m.\u001B[39mto(device), final_state\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/Desktop/QuantumDynamicsAI/QuantumSimulatorDataset.py:188\u001B[0m, in \u001B[0;36mQuantumSimulationDatasetFast.__getitem__\u001B[0;34m(self, _)\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, _):\n\u001B[0;32m--> 188\u001B[0m     initial_states, final_states \u001B[38;5;241m=\u001B[39m run_batch_dense_torch(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmat, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_qubits, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size,\n\u001B[1;32m    189\u001B[0m                                                          \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minverse_density)\n\u001B[1;32m    190\u001B[0m     initial_states \u001B[38;5;241m=\u001B[39m initial_states\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mexpand_as(final_states)\u001B[38;5;241m.\u001B[39mclone()\n\u001B[1;32m    191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m initial_states\u001B[38;5;241m.\u001B[39mflatten(end_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m), final_states\u001B[38;5;241m.\u001B[39mflatten(end_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Desktop/QuantumDynamicsAI/QuantumSimulatorDataset.py:170\u001B[0m, in \u001B[0;36mrun_batch_dense_torch\u001B[0;34m(unitary_circuit, num_qbits, batch_size, num_samples, device, inverse_density)\u001B[0m\n\u001B[1;32m    168\u001B[0m decimal \u001B[38;5;241m=\u001B[39m decimal_from_initial_state(bits, num_qbits)\n\u001B[1;32m    169\u001B[0m one_hot \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mone_hot(decimal, num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m num_qbits)\n\u001B[0;32m--> 170\u001B[0m final_state \u001B[38;5;241m=\u001B[39m get_final_state_vector(one_hot\u001B[38;5;241m.\u001B[39mcfloat(), unitary_circuit)\n\u001B[1;32m    171\u001B[0m sample \u001B[38;5;241m=\u001B[39m sample_from_state_vector(final_state, num_qbits, num_samples)\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m bits\u001B[38;5;241m.\u001B[39mfloat(), sample\n",
      "File \u001B[0;32m~/Desktop/QuantumDynamicsAI/QuantumSimulatorDataset.py:139\u001B[0m, in \u001B[0;36mget_final_state_vector\u001B[0;34m(batched_initial_state, op_mat)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_final_state_vector\u001B[39m(batched_initial_state, op_mat):\n\u001B[0;32m--> 139\u001B[0m     sampled_final_state \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(op_mat\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m), batched_initial_state\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m    140\u001B[0m     probs \u001B[38;5;241m=\u001B[39m sampled_final_state \u001B[38;5;241m*\u001B[39m sampled_final_state\u001B[38;5;241m.\u001B[39mconj()\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mreal(probs)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('Device:', device)\n",
    "    \n",
    "    # Dataset Hyperparameters\n",
    "    num_qbits = 12\n",
    "    num_final_per_initial = 4\n",
    "    inverse_density = 3\n",
    "    num_ones = int(num_qbits/inverse_density)\n",
    "    batch_size = 64\n",
    "    circuit_length = 2\n",
    "    \n",
    "    # Model Hyperparameters\n",
    "    # latent_spaces = [2,4,6,8,10,12]\n",
    "    latent_spaces = [4]\n",
    "    hidden_dim = 32\n",
    "    dropout = 0.1\n",
    "    learning_rate = 1e-2\n",
    "    num_steps = 5000\n",
    "    \n",
    "    dataset_hyperparams = (num_qbits, num_final_per_initial, inverse_density, num_ones, batch_size, circuit_length)    \n",
    "    model_hyperparams = (hidden_dim, dropout, learning_rate, num_steps)\n",
    "    \n",
    "    #losses, BAccs, MIs, expected MIs\n",
    "    all_loss_arrays = []\n",
    "    all_acc_arrays = []\n",
    "    all_mi_arrays = []\n",
    "    all_expected_mi_arrays = []\n",
    "\n",
    "    for i, (latent_space) in enumerate(latent_spaces):\n",
    "        temp_loss, temp_acc, temp_mi, temp_exmi = train_VAETransformer(*dataset_hyperparams, latent_space, *model_hyperparams, device)\n",
    "        all_loss_arrays.append(temp_loss)\n",
    "        all_acc_arrays.append(temp_acc)\n",
    "        all_mi_arrays.append(temp_mi)\n",
    "        all_expected_mi_arrays.append(temp_exmi)\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T20:33:46.949088Z",
     "start_time": "2024-08-20T20:23:22.666132Z"
    }
   },
   "id": "5598d4ad727565b4"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of rows must be a positive integer, not 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[60], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m plot_loss_accuracy(all_loss_arrays, all_acc_arrays, circuit_length, num_qbits, latent_spaces)\n\u001B[1;32m      2\u001B[0m plot_MI(all_mi_arrays, all_expected_mi_arrays, circuit_length, num_qbits, latent_spaces)\n",
      "Cell \u001B[0;32mIn[17], line 7\u001B[0m, in \u001B[0;36mplot_loss_accuracy\u001B[0;34m(all_loss_arrays, all_acc_arrays, circuit_length, num_qbits, latent_spaces)\u001B[0m\n\u001B[1;32m      4\u001B[0m num_cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m  \u001B[38;5;66;03m# Number of columns for the grid\u001B[39;00m\n\u001B[1;32m      5\u001B[0m num_rows \u001B[38;5;241m=\u001B[39m (num_plots \u001B[38;5;241m+\u001B[39m num_cols \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m num_cols  \u001B[38;5;66;03m# Calculate number of rows needed\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m fig, axes \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(num_rows, num_cols, figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m10\u001B[39m))\n\u001B[1;32m      8\u001B[0m axes \u001B[38;5;241m=\u001B[39m axes\u001B[38;5;241m.\u001B[39mflatten()  \u001B[38;5;66;03m# Flatten the array of axes for easy iteration\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (train_Loss, train_BAcc) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(all_loss_arrays, all_acc_arrays)):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/pyplot.py:1599\u001B[0m, in \u001B[0;36msubplots\u001B[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001B[0m\n\u001B[1;32m   1455\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1456\u001B[0m \u001B[38;5;124;03mCreate a figure and a set of subplots.\u001B[39;00m\n\u001B[1;32m   1457\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1596\u001B[0m \n\u001B[1;32m   1597\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1598\u001B[0m fig \u001B[38;5;241m=\u001B[39m figure(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfig_kw)\n\u001B[0;32m-> 1599\u001B[0m axs \u001B[38;5;241m=\u001B[39m fig\u001B[38;5;241m.\u001B[39msubplots(nrows\u001B[38;5;241m=\u001B[39mnrows, ncols\u001B[38;5;241m=\u001B[39mncols, sharex\u001B[38;5;241m=\u001B[39msharex, sharey\u001B[38;5;241m=\u001B[39msharey,\n\u001B[1;32m   1600\u001B[0m                    squeeze\u001B[38;5;241m=\u001B[39msqueeze, subplot_kw\u001B[38;5;241m=\u001B[39msubplot_kw,\n\u001B[1;32m   1601\u001B[0m                    gridspec_kw\u001B[38;5;241m=\u001B[39mgridspec_kw, height_ratios\u001B[38;5;241m=\u001B[39mheight_ratios,\n\u001B[1;32m   1602\u001B[0m                    width_ratios\u001B[38;5;241m=\u001B[39mwidth_ratios)\n\u001B[1;32m   1603\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fig, axs\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/figure.py:930\u001B[0m, in \u001B[0;36mFigureBase.subplots\u001B[0;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001B[0m\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwidth_ratios\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must not be defined both as \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    927\u001B[0m                          \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter and as key in \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgridspec_kw\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    928\u001B[0m     gridspec_kw[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwidth_ratios\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m width_ratios\n\u001B[0;32m--> 930\u001B[0m gs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_gridspec(nrows, ncols, figure\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgridspec_kw)\n\u001B[1;32m    931\u001B[0m axs \u001B[38;5;241m=\u001B[39m gs\u001B[38;5;241m.\u001B[39msubplots(sharex\u001B[38;5;241m=\u001B[39msharex, sharey\u001B[38;5;241m=\u001B[39msharey, squeeze\u001B[38;5;241m=\u001B[39msqueeze,\n\u001B[1;32m    932\u001B[0m                   subplot_kw\u001B[38;5;241m=\u001B[39msubplot_kw)\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m axs\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/figure.py:1542\u001B[0m, in \u001B[0;36mFigureBase.add_gridspec\u001B[0;34m(self, nrows, ncols, **kwargs)\u001B[0m\n\u001B[1;32m   1503\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1504\u001B[0m \u001B[38;5;124;03mReturn a `.GridSpec` that has this figure as a parent.  This allows\u001B[39;00m\n\u001B[1;32m   1505\u001B[0m \u001B[38;5;124;03mcomplex layout of Axes in the figure.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1538\u001B[0m \n\u001B[1;32m   1539\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1541\u001B[0m _ \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfigure\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)  \u001B[38;5;66;03m# pop in case user has added this...\u001B[39;00m\n\u001B[0;32m-> 1542\u001B[0m gs \u001B[38;5;241m=\u001B[39m GridSpec(nrows\u001B[38;5;241m=\u001B[39mnrows, ncols\u001B[38;5;241m=\u001B[39mncols, figure\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m gs\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/gridspec.py:378\u001B[0m, in \u001B[0;36mGridSpec.__init__\u001B[0;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001B[0m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhspace \u001B[38;5;241m=\u001B[39m hspace\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfigure \u001B[38;5;241m=\u001B[39m figure\n\u001B[0;32m--> 378\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(nrows, ncols,\n\u001B[1;32m    379\u001B[0m                  width_ratios\u001B[38;5;241m=\u001B[39mwidth_ratios,\n\u001B[1;32m    380\u001B[0m                  height_ratios\u001B[38;5;241m=\u001B[39mheight_ratios)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/gridspec.py:48\u001B[0m, in \u001B[0;36mGridSpecBase.__init__\u001B[0;34m(self, nrows, ncols, height_ratios, width_ratios)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;03m----------\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;124;03m    If not given, all rows will have the same height.\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(nrows, Integral) \u001B[38;5;129;01mor\u001B[39;00m nrows \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     49\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of rows must be a positive integer, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnrows\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ncols, Integral) \u001B[38;5;129;01mor\u001B[39;00m ncols \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     52\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of columns must be a positive integer, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mncols\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Number of rows must be a positive integer, not 0"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_accuracy(all_loss_arrays, all_acc_arrays, circuit_length, num_qbits, latent_spaces)\n",
    "plot_MI(all_mi_arrays, all_expected_mi_arrays, circuit_length, num_qbits, latent_spaces)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T20:12:54.748928Z",
     "start_time": "2024-08-20T20:12:54.376975Z"
    }
   },
   "id": "87c1b1d1de4ac86"
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 0.1, 0.01, 5000)\n",
      "(12, 4, 3, 4, 64, 2)\n",
      "[2, 4, 6, 8, 10, 12]\n"
     ]
    }
   ],
   "source": [
    "print(model_hyperparams)\n",
    "print(dataset_hyperparams)\n",
    "print(latent_spaces)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T17:10:20.851278Z",
     "start_time": "2024-07-24T17:10:20.787067Z"
    }
   },
   "id": "36fde4b34ca00403"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
